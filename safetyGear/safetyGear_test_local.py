# -------------------- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ --------------------
import cv2
import time
import numpy as np
import os
import torch
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort

# -------------------- 2. ì„¤ì • --------------------
# ëª¨ë¸ê³¼ ì˜ìƒ ê²½ë¡œ
MODEL_PATH = "./best.pt"
VIDEO_PATH = "./test_video.mp4"
OUTPUT_VIDEO_PATH = "./output_test_video.mp4"

# í´ë˜ìŠ¤ ì •ë³´ (YOLO í•™ìŠµ ì‹œ ì •ì˜í•œ ìˆœì„œì— ë§ê²Œ ìˆ˜ì •)
CLASS_NAMES = {
    0: "seatbelt_on",
    1: "lanyard_on",
    2: "helmet_on",
}

# í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì •ì˜ (ì„ íƒ)
CLASS_COLORS = {
    0: (0, 255, 0),       # seatbelt_on â†’ ì´ˆë¡
    1: (255, 255, 0),     # lanyard_on â†’ ë…¸ë‘
    2: (255, 0, 255),     # helmet_on â†’ ë³´ë¼
}

CONF_THRESHOLD = 0.5  # íƒì§€ ì‹ ë¢°ë„ ê¸°ì¤€

# -------------------- 3. ëª¨ë¸ ë° ë¹„ë””ì˜¤ ì´ˆê¸°í™” --------------------
model = YOLO(MODEL_PATH, task='detect') # task ëª…ì‹œ
model.to("cpu") # ëª…ì‹œì ìœ¼ë¡œ cpu ì‚¬ìš©

cap = cv2.VideoCapture(VIDEO_PATH)

if not cap.isOpened():
    raise IOError("ğŸš¨ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

video_writer = cv2.VideoWriter(
    OUTPUT_VIDEO_PATH,
    cv2.VideoWriter_fourcc(*'mp4v'),
    fps,
    (width, height)
)

# -------------------- 4. DeepSORT ì¶”ì ê¸° ì´ˆê¸°í™” --------------------
use_gpu = False             # CPU ê³ ì •
tracker = DeepSort(
    max_age=5,
    embedder='mobilenet',   # mobilenet -> osnet_x0_25 -> osnet_x1_0
    half=False,             # GPU ì—†ëŠ” ê²½ìš° half precision ì‚¬ìš© ê¸ˆì§€
    bgr=True,
    embedder_gpu=False      # CPU í™˜ê²½ì—ì„œëŠ” ë°˜ë“œì‹œ False
)

# -------------------- 5. ìœ í‹¸ í•¨ìˆ˜: ë°•ìŠ¤ ê·¸ë¦¬ê¸° --------------------
def draw_box(frame, bbox, track_id, cls_id):
    label = CLASS_NAMES.get(cls_id, f'class_{cls_id}')
    color = CLASS_COLORS.get(cls_id, (255, 255, 255))  # ê¸°ë³¸: í°ìƒ‰
    x1, y1, x2, y2 = map(int, bbox)
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    cv2.putText(frame, f'{label} ID:{track_id}', (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# -------------------- 6. ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ --------------------
frame_count = 0
start_time = time.time()
SKIP_FRAME = 5
frame_index = 0

# ğŸ’¡ í”„ë ˆì„ ìŠ¤í‚µ ëŒ€ì‘ìš©: ë§ˆì§€ë§‰ íƒì§€ ì •ë³´ ì €ì¥ ë³€ìˆ˜
last_tracked_objects = []         # (bbox, track_id, class_id) ë¦¬ìŠ¤íŠ¸
last_tracked_frame_index = -1     # ë§ˆì§€ë§‰ íƒì§€ í”„ë ˆì„ ë²ˆí˜¸

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âœ… ì˜ìƒ ì¢…ë£Œ ë˜ëŠ” í”„ë ˆì„ ì—†ìŒ")
        break

    frame_index += 1

    if frame_index % SKIP_FRAME == 0:
        # --- íƒì§€ ìˆ˜í–‰ ---
        results = model.predict(frame, conf=CONF_THRESHOLD, verbose=False)[0]
        detections = []
        for box, conf, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):
            x1, y1, x2, y2 = map(int, box)
            detections.append([[x1, y1, x2 - x1, y2 - y1], float(conf), int(cls)])

        tracks = tracker.update_tracks(detections, frame=frame)

        # ì¶”ì  ê²°ê³¼ ì €ì¥
        last_tracked_objects = []
        for track in tracks:
            if not track.is_confirmed():
                continue
            tid = track.track_id
            bbox = track.to_ltrb()
            cls_id = int(track.det_class)
            last_tracked_objects.append((bbox, tid, cls_id))
            draw_box(frame, bbox, tid, cls_id)

        last_tracked_frame_index = frame_index
    else:
        # --- ì´ì „ ì¶”ì  ê²°ê³¼ ì¬ì‚¬ìš© (ë³´ê°„) ---
        for bbox, tid, cls_id in last_tracked_objects:
            draw_box(frame, bbox, tid, cls_id)

    # FPS í‘œì‹œ
    frame_count += 1
    elapsed = time.time() - start_time
    fps_now = frame_count / elapsed
    cv2.putText(frame, f"FPS: {fps_now:.2f}", (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)

    video_writer.write(frame)

# -------------------- 7. ì¢…ë£Œ --------------------
cap.release()
video_writer.release()
cv2.destroyAllWindows()

print(f"ğŸ¬ íƒì§€ ì™„ë£Œ. ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {OUTPUT_VIDEO_PATH}")
