import os
import cv2
import json
import shutil
import random
import numpy as np
from PIL import Image
from collections import defaultdict
from skimage.measure import shannon_entropy
from concurrent.futures import ThreadPoolExecutor, as_completed

BASE_DIR = "D:/"
FOLDER_NAME = "6.ìƒì—…ì‹œì„¤_ì‹ ì‚¬ë™_ë³µí•©_ì‹œì„¤"

# ================== ì„¤ì • ==================
base_dir = os.path.normpath(BASE_DIR)
input_root = os.path.join(base_dir, FOLDER_NAME + "_filtered")
output_root = os.path.join(base_dir, FOLDER_NAME + "_completed")
split_set = ["train", "val"]
target_classes = {"01", "03", "07"}

# í´ë˜ìŠ¤ë‹¹ ëª©í‘œ ìˆ˜ëŸ‰ (splitë§ˆë‹¤ ë‹¤ë¦„)
per_class_target_map = {
    "train": 180,
    "val": 30
}

# ì´ë¯¸ì§€ í’ˆì§ˆ í•„í„°ë§ ê¸°ì¤€ (ì—„ê²©)
QUALITY_THRESHOLD = {
    'laplacian': 50,        # ì„ ëª…ë„
    'snr': 5,               # ì‹ í˜¸ëŒ€ì¡ìŒë¹„
    'entropy': 2.5,         # ì •ë³´ëŸ‰
    'brightness_min': 20,   # ìµœì†Œ ë°ê¸°
    'brightness_max': 240,  # ìµœëŒ€ ë°ê¸°
    'contrast': 10          # ëª…ì•” ëŒ€ë¹„
}

# í’ˆì§ˆ ê¸°ì¤€ ì™„í™”ê°’ (ì¶©ì¡± ì´ë¯¸ì§€ ë¶€ì¡± ì‹œ ì‚¬ìš©)
RELAXED_THRESHOLD = {
    'laplacian': 20,
    'snr': 2,
    'entropy': 1.5,
    'brightness_min': 10,
    'brightness_max': 250,
    'contrast': 5
}
# ==========================================

# ì†ìƒëœ ì´ë¯¸ì§€ ì œê±°
def remove_corrupted_images(images_dir):
    removed = 0
    for fname in os.listdir(images_dir):
        if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
            continue
        path = os.path.join(images_dir, fname)
        try:
            with Image.open(path) as img:
                img.verify()
        except Exception:
            os.remove(path)
            removed += 1
            print(f"âŒ ì‚­ì œëœ ì†ìƒ ì´ë¯¸ì§€: {fname}")
    return removed

# ì£¼ì–´ì§„ ì´ë¯¸ì§€ê°€ í’ˆì§ˆ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ì§€ í™•ì¸
def is_high_quality(image_path, threshold):
    try:
        image = Image.open(image_path).convert("L").resize((512, 512))
        image_np = np.array(image)

        # í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
        lap = cv2.Laplacian(image_np, cv2.CV_64F).var() # ì„ ëª…ë„
        mean = np.mean(image_np)                        # ë°ê¸°
        stddev = np.std(image_np)                       # ë°ê¸° í‘œì¤€í¸ì°¨
        snr = mean / stddev if stddev > 0 else 0        # SNR
        entropy = shannon_entropy(image_np)             # ì—”íŠ¸ë¡œí”¼

        # ì¡°ê±´ ë§Œì¡± ì—¬ë¶€ í™•ì¸
        if lap < threshold['laplacian']: return False
        if snr < threshold['snr']: return False
        if entropy < threshold['entropy']: return False
        if not (threshold['brightness_min'] < mean < threshold['brightness_max']): return False
        if stddev < threshold['contrast']: return False

        return True
    except Exception:
        return False

# í•˜ë‚˜ì˜ í›„ë³´ ì´ë¯¸ì§€ì— ëŒ€í•´ í’ˆì§ˆ í‰ê°€
def evaluate_candidate(args):
    json_file, filename, class_set, threshold, in_images_dir = args
    img_path = os.path.join(in_images_dir, filename)
    if not os.path.exists(img_path):
        return None
    if is_high_quality(img_path, threshold):
        return (json_file, filename, class_set)
    return None

# í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ ì§‘ê³„
class_counts = defaultdict(int)

# train / val ê°ê° ì²˜ë¦¬
for split in split_set:
    print(f"\nğŸ”„ {split.upper()} ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")

    # í˜„ì¬ split(train / val)ì— í•´ë‹¹í•˜ëŠ” ëª©í‘œ ìˆ˜ëŸ‰(180, 30)
    per_class_target = per_class_target_map[split]

    # ì…ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    in_labels_dir = os.path.join(input_root, split, "labels_json")
    in_images_dir = os.path.join(input_root, split, "images")
    out_labels_dir = os.path.join(output_root, split, "labels_json")
    out_images_dir = os.path.join(output_root, split, "images")
    os.makedirs(out_labels_dir, exist_ok=True)
    os.makedirs(out_images_dir, exist_ok=True)

    # ì†ìƒëœ ì´ë¯¸ì§€ ì œê±°
    remove_corrupted_images(in_images_dir)

    # í´ë˜ìŠ¤ë³„ë¡œ ì„ íƒëœ íŒŒì¼ ì €ì¥ìš© ì„ ì–¸
    selected = {cls: set() for cls in target_classes}
    candidates = []

    # í´ë˜ìŠ¤ë³„ í›„ë³´ ìˆ˜ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    candidate_class_counts = defaultdict(int)

    # í›„ë³´ ì´ë¯¸ì§€ íƒìƒ‰
    for json_file in os.listdir(in_labels_dir):
        if not json_file.endswith(".json"):
            continue
        json_path = os.path.join(in_labels_dir, json_file)
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        annotations = data.get("annotations", [])
        classes = {ann.get("class") for ann in annotations}
        valid = classes & target_classes    # íƒ€ê²Ÿ í´ë˜ìŠ¤ í¬í•¨ ì—¬ë¶€ í™•ì¸
        if not valid:
            continue

        filename = data.get("image", {}).get("filename", "")
        img_path = os.path.join(in_images_dir, filename)
        if not filename or not os.path.exists(img_path):
            continue

        # ê° í´ë˜ìŠ¤ë³„ë¡œ ì¹´ìš´íŠ¸ ì¦ê°€
        for cls in valid:
            if cls in target_classes:
                candidate_class_counts[cls] += 1
        
        # í›„ë³´ë¡œ ì¶”ê°€
        candidates.append((json_file, filename, valid))

    # í›„ë³´ íƒìƒ‰ ê²°ê³¼ ì¶œë ¥
    print(f"âœ… ì „ì²´ í›„ë³´ ìˆ˜: {len(candidates)}ì¥")
    for cls in sorted(target_classes):
        print(f"   â”” í´ë˜ìŠ¤ {cls}: {candidate_class_counts[cls]}ì¥")

    random.seed(42)             # ì‹œë“œ ê³ ì •
    random.shuffle(candidates)  # ëœë¤ ì…”í”Œë¡œ ë‹¤ì–‘ì„± í™•ë³´

    # ë³‘ë ¬ë¡œ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜
    def parallel_filter(threshold):
        args_list = [(json_file, filename, class_set, threshold, in_images_dir)
                     for json_file, filename, class_set in candidates]

        # ë³‘ë ¬ ì²˜ë¦¬(ìµœëŒ€ 8ê°œ ìŠ¤ë ˆë“œ ì‚¬ìš©)
        with ThreadPoolExecutor(max_workers=8) as executor:
            for future in as_completed([executor.submit(evaluate_candidate, args) for args in args_list]):
                result = future.result()
                if not result:
                    continue
                json_file, filename, class_set = result

                # í´ë˜ìŠ¤ë³„ë¡œ quota ì´ˆê³¼í•˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ ì¶”ê°€
                for cls in class_set:
                    if cls in target_classes and len(selected[cls]) < per_class_target:
                        selected[cls].add((json_file, filename))
                        break

    # 1ì°¨ í•„í„°: ì—„ê²© ê¸°ì¤€
    parallel_filter(QUALITY_THRESHOLD)

    # 2ì°¨ í•„í„°: ë¶€ì¡±í•œ í´ë˜ìŠ¤ì— í•œí•´ ì™„í™” ê¸°ì¤€ ì ìš©
    for cls in target_classes:
        if len(selected[cls]) < per_class_target:
            print(f"âš ï¸ í´ë˜ìŠ¤ {cls}: {per_class_target - len(selected[cls])}ì¥ ë¶€ì¡± â†’ ê¸°ì¤€ ì™„í™”")
            parallel_filter(RELAXED_THRESHOLD)

    # ìµœì¢… ì„ íƒëœ ì´ë¯¸ì§€ ë° ë¼ë²¨ ë³µì‚¬
    for cls, files in selected.items():
        count = min(len(files), per_class_target)
        for json_file, fname in list(files)[:count]:
            # í´ë˜ìŠ¤ë³„ í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±
            img_class_dir = os.path.join(out_images_dir, cls)
            json_class_dir = os.path.join(out_labels_dir, cls)

            src_img = os.path.join(in_images_dir, fname)
            dst_img = os.path.join(img_class_dir, fname)
            src_json = os.path.join(in_labels_dir, json_file)
            dst_json = os.path.join(json_class_dir, json_file)

            if not os.path.exists(src_img):
                continue

            os.makedirs(os.path.dirname(dst_img), exist_ok=True)
            os.makedirs(os.path.dirname(dst_json), exist_ok=True)

            shutil.copy(src_img, dst_img)
            shutil.copy(src_json, dst_json)
            class_counts[f"{split}_{cls}"] += 1

# ìµœì¢… ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š ìµœì¢… ê²°ê³¼")
for key in sorted(class_counts.keys()):
    print(f"{key}: {class_counts[key]}ì¥")
print(f"ì´ ì €ì¥ ì´ë¯¸ì§€ ìˆ˜: {sum(class_counts.values())}ì¥")