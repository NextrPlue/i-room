# -------------------- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ --------------------
import cv2
import time
import numpy as np
import os
import torch
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort

# -------------------- 2. ì„¤ì • --------------------
MODEL_PATH = 'model/best_8n_finished_v3.pt'
VIDEO_PATH = "test2.mp4"
OUTPUT_VIDEO_PATH = "output_deepsort_gpu.mp4"

CLASS_NAMES = {
    0: "seatbelt_on",
    1: "helmet_on",
}

CLASS_COLORS = {
    0: (0, 255, 0),
    1: (0, 0, 255),
    2: (255, 255, 0),
    3: (0, 255, 255),
    4: (255, 0, 255),
    5: (255, 0, 0),
}

CONF_THRESHOLD = 0.35

# -------------------- 3. ëª¨ë¸ ë° ë¹„ë””ì˜¤ ì´ˆê¸°í™” --------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ“Œ Using device: {device}")

model = YOLO(MODEL_PATH)
model.to(device)

cap = cv2.VideoCapture(VIDEO_PATH)
if not cap.isOpened():
    raise IOError("ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

video_writer = cv2.VideoWriter(
    OUTPUT_VIDEO_PATH,
    cv2.VideoWriter_fourcc(*'mp4v'),
    fps,
    (width, height)
)

# -------------------- 4. DeepSORT ì¶”ì ê¸° ì´ˆê¸°í™” --------------------
use_gpu = torch.cuda.is_available()
tracker = DeepSort(
    max_age=15,
    n_init=2,
    embedder='mobilenet',  
    half=True,
    bgr=True,
    embedder_gpu=use_gpu
)


# -------------------- 5. ìœ í‹¸ í•¨ìˆ˜ --------------------
def draw_box(frame, bbox, track_id, cls_id):
    label = CLASS_NAMES.get(cls_id, f'class_{cls_id}')
    color = CLASS_COLORS.get(cls_id, (255, 255, 255))
    x1, y1, x2, y2 = map(int, bbox)
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    cv2.putText(frame, f'{label} ID:{track_id}', (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# -------------------- 6. ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ --------------------
frame_count = 0
start_time = time.time()

# track_idë³„ í´ë˜ìŠ¤ ê¸°ë¡ìš© ë”•ì…”ë„ˆë¦¬
track_class_map = {}

# YOLO ì…ë ¥ í¬ê¸° ì§€ì •
TARGET_SIZE = (640, 640)

# íƒì§€ ì£¼ê¸° ì„¤ì • (ì˜ˆ: 5í”„ë ˆì„ë§ˆë‹¤ íƒì§€)
DETECTION_INTERVAL = 5

# ìµœê·¼ íƒì§€ ê²°ê³¼ ì €ì¥
last_detections = []
last_cls_list = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âœ… ì˜ìƒ ì¢…ë£Œ ë˜ëŠ” í”„ë ˆì„ ì—†ìŒ")
        break

    # í”„ë ˆì„ í¬ê¸°ë¥¼ 640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    frame = cv2.resize(frame, TARGET_SIZE)

    detections = []
    cls_list = []

    # ì§€ì •ëœ ì£¼ê¸°ë§ˆë‹¤ YOLO íƒì§€ ì‹¤í–‰
    if frame_count % DETECTION_INTERVAL == 0:
        results = model.predict(frame, conf=CONF_THRESHOLD, device=device, verbose=False)[0]
        for box, conf, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):
            x1, y1, x2, y2 = map(int, box)
            detections.append([[x1, y1, x2 - x1, y2 - y1], float(conf), int(cls)])
            cls_list.append(int(cls))

        # íƒì§€ ê²°ê³¼ ê°±ì‹ 
        last_detections = detections
        last_cls_list = cls_list
    else:
        # ì´ì „ íƒì§€ ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        detections = last_detections
        cls_list = last_cls_list

    # DeepSORT ì¶”ì 
    tracks = tracker.update_tracks(detections, frame=frame)

    for i, track in enumerate(tracks):
        if not track.is_confirmed():
            continue

        tid = track.track_id
        bbox = track.to_ltrb()

        if tid not in track_class_map and i < len(cls_list):
            track_class_map[tid] = cls_list[i]

        cls_id = track_class_map.get(tid, 0)
        draw_box(frame, bbox, tid, cls_id)

    # FPS í‘œì‹œ
    frame_count += 1
    elapsed = time.time() - start_time
    fps_now = frame_count / elapsed
    cv2.putText(frame, f"FPS: {fps_now:.2f}", (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)

    # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
    video_writer.write(frame)
    cv2.imshow('YOLOv8 + DeepSORT Tracking (Interval Detection)', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break